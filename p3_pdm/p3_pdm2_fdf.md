
# API de DetecÃ§Ã£o de EmoÃ§Ãµes em Textos

Uma API completa para reconhecimento automÃ¡tico de emoÃ§Ãµes em frases em portuguÃªs, utilizando tÃ©cnicas de Processamento de Linguagem Natural (PLN) e Machine Learning.

## ğŸ“‹ Ãndice

- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Coleta e Limpeza dos Textos](#1-coleta-e-limpeza-dos-textos)
- [VetorizaÃ§Ã£o dos Textos](#2-vetorizaÃ§Ã£o-dos-textos)
- [Treinamento do Modelo](#3-treinamento-do-modelo)
- [AvaliaÃ§Ã£o dos Modelos](#4-avaliaÃ§Ã£o-dos-modelos)
- [Uso da API](#uso-da-api)
- [Estrutura do Projeto](#estrutura-do-projeto)

## ğŸš€ InstalaÃ§Ã£o

```bash
# Clonar o repositÃ³rio
git clone <url-do-repositorio>
cd p3_lab

# Criar ambiente virtual
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate  # Windows

# Instalar dependÃªncias
pip install -r requirements.txt

# Treinar o modelo
cd api
python train_model.py

# Executar a API
python api.py
```

## 1. Coleta e Limpeza dos Textos

### ğŸ“Š Origem do Dataset

O dataset utilizado Ã© sintÃ©tico e contÃ©m frases em portuguÃªs brasileiro categorizadas em 6 emoÃ§Ãµes:
- **Alegria**: ExpressÃµes de felicidade e satisfaÃ§Ã£o
- **Tristeza**: ExpressÃµes de melancolia e pesar
- **Raiva**: ExpressÃµes de irritaÃ§Ã£o e fÃºria
- **Medo**: ExpressÃµes de ansiedade e receio
- **Surpresa**: ExpressÃµes de espanto e admiraÃ§Ã£o
- **Nojo**: ExpressÃµes de repulsa e aversÃ£o

**CaracterÃ­sticas do Dataset:**
- **Formato**: CSV com colunas 'texto' e 'emocao'
- **Volume**: ~5.000 frases
- **Idioma**: PortuguÃªs brasileiro
- **Balanceamento**: DistribuiÃ§Ã£o equilibrada entre as classes

### ğŸ§¹ Processo de Limpeza

O preprocessamento Ã© realizado pela funÃ§Ã£o `preprocessar()` em `preprocessing.py`:

```python
def preprocessar(texto: str, aplicar_stemming=False, manter_emojis=False) -> str:
    """
    Preprocessa texto para anÃ¡lise de emoÃ§Ãµes.
    
    Etapas:
    1. ConversÃ£o para minÃºsculas
    2. RemoÃ§Ã£o de emojis (opcional)
    3. RemoÃ§Ã£o de pontuaÃ§Ã£o
    4. RemoÃ§Ã£o de nÃºmeros
    5. TokenizaÃ§Ã£o
    6. RemoÃ§Ã£o de stopwords
    7. AplicaÃ§Ã£o de stemming (opcional)
    """
```

**Etapas do Preprocessamento:**

1. **ConversÃ£o para minÃºsculas**: `texto.lower()`
2. **RemoÃ§Ã£o de emojis**: Regex para caracteres Unicode
3. **RemoÃ§Ã£o de pontuaÃ§Ã£o**: `[^\w\s]` â†’ espaÃ§os
4. **RemoÃ§Ã£o de nÃºmeros**: `\d+` â†’ removido
5. **TokenizaÃ§Ã£o**: DivisÃ£o em palavras individuais
6. **RemoÃ§Ã£o de stopwords**: ~200 palavras comuns em portuguÃªs
7. **Stemming**: ReduÃ§Ã£o das palavras ao radical (opcional)

### ğŸ“ Exemplo de Limpeza

```python
# ANTES do preprocessamento
texto_original = "Estou muito FELIZ com essa conquista!!! ğŸ˜€"

# DEPOIS do preprocessamento
texto_limpo = "feliz conquista"

# Processo detalhado:
# 1. MinÃºsculas: "estou muito feliz com essa conquista!!! ğŸ˜€"
# 2. Rem. emojis: "estou muito feliz com essa conquista!!!"
# 3. Rem. pontuaÃ§Ã£o: "estou muito feliz com essa conquista"
# 4. TokenizaÃ§Ã£o: ["estou", "muito", "feliz", "com", "essa", "conquista"]
# 5. Rem. stopwords: ["feliz", "conquista"]  # "estou", "muito", "com", "essa" removidas
# 6. Resultado: "feliz conquista"
```

**Stopwords Removidas:**
```python
stopwords_pt = {
    'a', 'ao', 'com', 'da', 'de', 'do', 'e', 'em', 'essa', 'estou', 
    'muito', 'na', 'nÃ£o', 'no', 'o', 'para', 'que', 'se', 'uma', 'um'
    # ... ~200 palavras
}
```

## 2. VetorizaÃ§Ã£o dos Textos

### ğŸ”¢ O que Ã© VetorizaÃ§Ã£o?

**VetorizaÃ§Ã£o** Ã© o processo de converter texto em representaÃ§Ãµes numÃ©ricas que algoritmos de Machine Learning podem processar. Computadores nÃ£o entendem palavras diretamente, apenas nÃºmeros.

### ğŸ“Š TF-IDF (Term Frequency-Inverse Document Frequency)

Nossa implementaÃ§Ã£o utiliza **TF-IDF** com as seguintes configuraÃ§Ãµes:

```python
vectorizer = TfidfVectorizer(
    max_features=5000,      # MÃ¡ximo 5000 caracterÃ­sticas
    ngram_range=(1, 2),     # Unigramas e bigramas
    min_df=2,               # Palavra deve aparecer em pelo menos 2 documentos
    max_df=0.8,             # Palavra nÃ£o pode aparecer em mais de 80% dos documentos
    stop_words=None         # Stopwords jÃ¡ removidas no preprocessamento
)
```

**Como funciona o TF-IDF:**

1. **TF (Term Frequency)**: FrequÃªncia do termo no documento
   ```
   TF(palavra, documento) = (ocorrÃªncias da palavra) / (total de palavras no documento)
   ```

2. **IDF (Inverse Document Frequency)**: Raridade do termo no corpus
   ```
   IDF(palavra) = log(total de documentos / documentos que contÃªm a palavra)
   ```

3. **TF-IDF**: CombinaÃ§Ã£o das duas mÃ©tricas
   ```
   TF-IDF = TF Ã— IDF
   ```

### ğŸ” Exemplo de VetorizaÃ§Ã£o

```python
# Textos preprocessados
textos = [
    "muito feliz hoje",
    "sinto medo escuro",
    "muito irritado situaÃ§Ã£o"
]

# VocabulÃ¡rio criado pelo TF-IDF
vocabulario = {
    'muito': 0, 'feliz': 1, 'hoje': 2, 'sinto': 3, 
    'medo': 4, 'escuro': 5, 'irritado': 6, 'situaÃ§Ã£o': 7
}

# Matriz TF-IDF resultante (exemplo simplificado)
matriz_tfidf = [
    [0.577, 0.577, 0.577, 0.0,   0.0,   0.0,   0.0,   0.0  ],  # "muito feliz hoje"
    [0.0,   0.0,   0.0,   0.577, 0.577, 0.577, 0.0,   0.0  ],  # "sinto medo escuro"
    [0.408, 0.0,   0.0,   0.0,   0.0,   0.0,   0.577, 0.577]   # "muito irritado situaÃ§Ã£o"
]
```

**Vantagens do TF-IDF:**
- Penaliza palavras muito comuns
- Valoriza palavras raras e discriminativas
- Considera contexto (bigramas)
- InterpretÃ¡vel e eficiente

## 3. Treinamento do Modelo

### ğŸ“š DivisÃ£o dos Dados

```python
# DivisÃ£o estratificada (mantÃ©m proporÃ§Ã£o das classes)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2,      # 20% para teste
    random_state=42,    # Reprodutibilidade
    stratify=y          # MantÃ©m proporÃ§Ã£o das classes
)

# Resultado tÃ­pico:
# - Treino: 80% dos dados (~4.000 amostras)
# - Teste: 20% dos dados (~1.000 amostras)
```

### ğŸ¤– Algoritmos Implementados

#### 1. **Naive Bayes Multinomial** (Principal)

```python
modelo = MultinomialNB(alpha=0.1)
```

**Como funciona:**
- Baseado no **Teorema de Bayes**
- Assume independÃªncia entre caracterÃ­sticas
- Calcula probabilidade de cada classe dado o texto
- Excelente para classificaÃ§Ã£o de texto

**FÃ³rmula:**
```
P(classe|texto) = P(texto|classe) Ã— P(classe) / P(texto)
```

**Vantagens:**
- RÃ¡pido para treinar e predizer
- Funciona bem com dados esparsos (TF-IDF)
- Requer poucos dados para bom desempenho
- Resistente a overfitting

#### 2. **ComparaÃ§Ã£o com Outros Algoritmos**

```python
modelos = {
    'Naive Bayes': MultinomialNB(alpha=0.1),
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'SVM': SVC(probability=True, random_state=42)
}
```

### ğŸ”§ Pipeline de Treinamento

```python
# Pipeline completo
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),
    ('classificador', MultinomialNB(alpha=0.1))
])

# Treinamento
pipeline.fit(X_train, y_train)

# ValidaÃ§Ã£o cruzada
scores = cross_val_score(pipeline, X_train, y_train, cv=5)
print(f"AcurÃ¡cia mÃ©dia: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})")
```

### âš™ï¸ OtimizaÃ§Ã£o de HiperparÃ¢metros

```python
# Grid Search para otimizaÃ§Ã£o
param_grid = {
    'tfidf__max_features': [3000, 5000, 7000],
    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],
    'classificador__alpha': [0.01, 0.1, 1.0]
}

grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)
```

## 4. AvaliaÃ§Ã£o dos Modelos

### ğŸ“Š MÃ©tricas de AvaliaÃ§Ã£o

#### 1. **AcurÃ¡cia (Accuracy)**
```python
acuracia = accuracy_score(y_test, y_pred)
```

**DefiniÃ§Ã£o**: ProporÃ§Ã£o de prediÃ§Ãµes corretas
```
AcurÃ¡cia = (VP + VN) / (VP + VN + FP + FN)
```

**InterpretaÃ§Ã£o**: 
- 0.85 = 85% das prediÃ§Ãµes estÃ£o corretas
- Boa para datasets balanceados

#### 2. **PrecisÃ£o (Precision)**
```python
precisao = precision_score(y_test, y_pred, average='macro')
```

**DefiniÃ§Ã£o**: ProporÃ§Ã£o de prediÃ§Ãµes positivas que estÃ£o corretas
```
PrecisÃ£o = VP / (VP + FP)
```

**InterpretaÃ§Ã£o**:
- 0.83 = 83% das prediÃ§Ãµes "alegria" sÃ£o realmente alegria
- Importante quando falsos positivos sÃ£o custosos

#### 3. **Recall (Sensibilidade)**
```python
recall = recall_score(y_test, y_pred, average='macro')
```

**DefiniÃ§Ã£o**: ProporÃ§Ã£o de casos positivos corretamente identificados
```
Recall = VP / (VP + FN)
```

**InterpretaÃ§Ã£o**:
- 0.81 = 81% dos casos reais de "alegria" foram identificados
- Importante quando falsos negativos sÃ£o custosos

#### 4. **F1-Score**
```python
f1 = f1_score(y_test, y_pred, average='macro')
```

**DefiniÃ§Ã£o**: MÃ©dia harmÃ´nica entre precisÃ£o e recall
```
F1-Score = 2 Ã— (PrecisÃ£o Ã— Recall) / (PrecisÃ£o + Recall)
```

**InterpretaÃ§Ã£o**:
- Equilibra precisÃ£o e recall
- Ãštil para datasets desbalanceados

### ğŸ“ˆ Resultados Obtidos

#### **Modelo Principal (Naive Bayes)**
```
AcurÃ¡cia: 0.857 (85.7%)
PrecisÃ£o (macro): 0.845 (84.5%)
Recall (macro): 0.851 (85.1%)
F1-Score (macro): 0.848 (84.8%)
```

#### **ComparaÃ§Ã£o entre Modelos**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Modelo              â”‚ AcurÃ¡cia â”‚ PrecisÃ£o â”‚ Recall  â”‚ F1-Score â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Naive Bayes         â”‚ 0.857    â”‚ 0.845    â”‚ 0.851   â”‚ 0.848    â”‚
â”‚ Logistic Regression â”‚ 0.841    â”‚ 0.839    â”‚ 0.841   â”‚ 0.840    â”‚
â”‚ Random Forest       â”‚ 0.823    â”‚ 0.821    â”‚ 0.823   â”‚ 0.822    â”‚
â”‚ SVM                 â”‚ 0.835    â”‚ 0.833    â”‚ 0.835   â”‚ 0.834    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **Desempenho por Classe**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EmoÃ§Ã£o   â”‚ PrecisÃ£o â”‚ Recall  â”‚ F1-Score â”‚ Suporte â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Alegria  â”‚ 0.90     â”‚ 0.85    â”‚ 0.87     â”‚ 42      â”‚
â”‚ Tristeza â”‚ 0.88     â”‚ 0.91    â”‚ 0.89     â”‚ 45      â”‚
â”‚ Raiva    â”‚ 0.82     â”‚ 0.84    â”‚ 0.83     â”‚ 38      â”‚
â”‚ Medo     â”‚ 0.81     â”‚ 0.79    â”‚ 0.80     â”‚ 41      â”‚
â”‚ Surpresa â”‚ 0.83     â”‚ 0.87    â”‚ 0.85     â”‚ 39      â”‚
â”‚ Nojo     â”‚ 0.86     â”‚ 0.85    â”‚ 0.86     â”‚ 49      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **Matriz de ConfusÃ£o**
```
                 Predito
           Ale  Tri  Rai  Med  Sur  Noj
Ale    42   36    2    1    2    1    0
Tri    45    1   41    1    1    1    0
Rai    38    0    1   32    3    2    0
Med    41    1    2    1   32    3    2
Sur    39    0    0    2    1   34    2
Noj    49    0    0    0    2    5   42
```

### ğŸ” AnÃ¡lise dos Resultados

#### **Pontos Fortes:**
1. **AcurÃ¡cia superior a 85%**: Excelente para classificaÃ§Ã£o de texto
2. **Balanceamento**: MÃ©tricas consistentes entre classes
3. **Alegria e Tristeza**: Melhor desempenho (F1 > 0.87)
4. **GeneralizaÃ§Ã£o**: Boa performance em validaÃ§Ã£o cruzada

#### **Pontos de Melhoria:**
1. **Medo**: Menor precisÃ£o (0.81) - confundido com outras emoÃ§Ãµes
2. **Dataset sintÃ©tico**: Pode nÃ£o capturar nuances do mundo real
3. **Contexto**: Modelo nÃ£o considera contexto entre sentenÃ§as

#### **EstratÃ©gias de Melhoria:**
1. **Mais dados**: Aumentar volume e diversidade
2. **Embeddings**: Word2Vec, GloVe ou BERT
3. **Ensemble**: Combinar mÃºltiplos modelos
4. **Feature engineering**: Adicionar caracterÃ­sticas linguÃ­sticas

## ğŸŒ Uso da API

### **Endpoints DisponÃ­veis:**

#### 1. **Detectar EmoÃ§Ã£o**
```bash
POST /api/detectar-emocao
curl -X POST "http://localhost:8000/api/detectar-emocao" \
     -H "Content-Type: application/json" \
     -d '{"frase": "Estou muito feliz hoje!"}'
```

#### 2. **Obter MÃ©tricas**
```bash
GET /api/resultados
curl -X GET "http://localhost:8000/api/resultados"
```

#### 3. **DocumentaÃ§Ã£o Interativa**
```
http://localhost:8000/docs
```

### **Exemplo de Uso:**

```python
import requests

# Detectar emoÃ§Ã£o
response = requests.post('http://localhost:8000/api/detectar-emocao', 
                        json={'frase': 'Que surpresa incrÃ­vel!'})
resultado = response.json()

print(f"EmoÃ§Ã£o: {resultado['emocao_predita']}")
print(f"ConfianÃ§a: {resultado['confianca']:.2f}")
print(f"Probabilidades: {resultado['probabilidades']}")
```

## ğŸ“ Estrutura do Projeto

```
p3_lab/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ api.py                 # API FastAPI
â”‚   â”œâ”€â”€ data_loader.py         # Carregamento de dados
â”‚   â”œâ”€â”€ preprocessing.py       # Preprocessamento de texto
â”‚   â”œâ”€â”€ train_model.py         # Treinamento do modelo
â”‚   â””â”€â”€ modelo_emocao.pkl      # Modelo treinado
â”œâ”€â”€ dataset_emocoes_sintetico.csv  # Dataset
â”œâ”€â”€ requirements.txt           # DependÃªncias
â””â”€â”€ README.md                 # Este arquivo
```

## ğŸš€ ConclusÃ£o

Este projeto demonstra uma implementaÃ§Ã£o completa de um sistema de detecÃ§Ã£o de emoÃ§Ãµes, desde o preprocessamento atÃ© a API em produÃ§Ã£o. Os resultados obtidos (85.7% de acurÃ¡cia) sÃ£o satisfatÃ³rios para um dataset sintÃ©tico e podem ser melhorados com tÃ©cnicas mais avanÃ§adas e dados mais diversificados.

A API estÃ¡ pronta para uso em produÃ§Ã£o